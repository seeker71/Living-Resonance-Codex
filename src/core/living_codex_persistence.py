#!/usr/bin/env python3
"""
Living Codex Persistence System
Handles complete system state persistence and restoration
"""

import json
import os
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, Optional
from collections import defaultdict

class LivingCodexPersistence:
    """
    Comprehensive persistence system for the Living Codex
    Handles saving and restoring all system state
    """
    
    def __init__(self, persistence_file: str = "living_codex_complete_state.json"):
        self.persistence_file = Path(persistence_file)
        self.state = {}
        self.last_save_time = None
        self.last_load_time = None
        
        print(f"ðŸŒŸ Living Codex Persistence System initialized")
        print(f"   ðŸ“ Persistence file: {self.persistence_file}")
        print(f"   ðŸ’¾ State persistence enabled")
        print(f"   ðŸ”„ Auto-restoration enabled")
    
    def save_system_state(self, universal_system, fractal_system, ai_system, 
                         self_gen_system, vibrational_system, governance_system) -> bool:
        """
        Save complete system state to file
        
        Args:
            universal_system: Universal Knowledge Representation System
            fractal_system: Fractal Recursion System
            ai_system: Advanced AI Integration System
            self_gen_system: Self-Generating System
            vibrational_system: Vibrational Axes System
            governance_system: Resonance Governance System
        
        Returns:
            True if save successful, False otherwise
        """
        try:
            print(f"\nðŸ’¾ Saving complete Living Codex system state...")
            
            # Collect state from all systems
            state = {
                "metadata": {
                    "save_timestamp": datetime.now().isoformat(),
                    "system_version": "2.0.0",
                    "total_systems": 6
                },
                "universal_system": {
                    "universal_concepts": self._serialize_concepts(universal_system.universal_concepts),
                    "concept_transformations": self._serialize_transformations(universal_system.concept_transformations),
                    "meta_circular_architectures": self._serialize_architectures(universal_system.meta_circular_architectures),
                    "knowledge_expansions": self._serialize_expansions(universal_system.knowledge_expansions),
                    "concept_to_node_mapping": universal_system.concept_to_node_mapping,
                    "node_to_concept_mapping": universal_system.node_to_concept_mapping
                },
                "fractal_system": {
                    "fractal_nodes": self._serialize_fractal_nodes(fractal_system.fractal_nodes),
                    "fractal_relationships": dict(fractal_system.fractal_relationships),
                    "cross_scale_mappings": fractal_system.cross_scale_mappings,
                    "fractal_patterns": list(fractal_system.fractal_patterns),
                    "exploration_cache": fractal_system.exploration_cache
                },
                "ai_system": {
                    "ai_agents": self._serialize_ai_agents(ai_system.ai_agents),
                    "consciousness_decisions": self._serialize_decisions(ai_system.consciousness_decisions),
                    "autonomous_explorations": self._serialize_explorations(ai_system.autonomous_explorations),
                    "ai_evolutions": self._serialize_evolutions(ai_system.ai_evolutions),
                    "agent_consciousness_history": dict(ai_system.agent_consciousness_history)
                },
                "self_gen_system": {
                    "discovered_concepts": self._serialize_concepts(self_gen_system.discovered_concepts),
                    "generated_specifications": self._serialize_specifications(self_gen_system.generated_specifications),
                    "ontological_evolutions": self._serialize_evolutions(self_gen_system.ontological_evolutions),
                    "concept_relationships": dict(self_gen_system.concept_relationships),
                    "evolution_history": self_gen_system.evolution_history
                },
                "vibrational_system": {
                    "vibrational_axes": vibrational_system.vibrational_axes,
                    "resonance_states": dict(vibrational_system.resonance_states),
                    "community_resonance": dict(vibrational_system.community_resonance),
                    "fractal_recursion_cache": vibrational_system.fractal_recursion_cache,
                    "cross_scale_cache": vibrational_system.cross_scale_cache
                },
                "governance_system": {
                    "resonance_decisions": self._serialize_decisions(governance_system.resonance_decisions),
                    "coherence_fields": self._serialize_fields(governance_system.coherence_fields),
                    "collective_intelligence": self._serialize_intelligence(governance_system.collective_intelligence),
                    "node_resonance_history": dict(governance_system.node_resonance_history),
                    "system_coherence_history": governance_system.system_coherence_history,
                    "governance_rules": governance_system.governance_rules
                }
            }
            
            # Save to file
            with open(self.persistence_file, 'w') as f:
                json.dump(state, f, indent=2, default=str)
            
            self.state = state
            self.last_save_time = datetime.now()
            
            # Calculate statistics
            total_concepts = len(state["universal_system"]["universal_concepts"])
            total_fractal_nodes = len(state["fractal_system"]["fractal_nodes"])
            total_ai_agents = len(state["ai_system"]["ai_agents"])
            
            print(f"âœ… System state saved successfully!")
            print(f"   ðŸ“Š Statistics:")
            print(f"      - Universal concepts: {total_concepts}")
            print(f"      - Fractal nodes: {total_fractal_nodes}")
            print(f"      - AI agents: {total_ai_agents}")
            print(f"      - File size: {self.persistence_file.stat().st_size / 1024:.1f} KB")
            print(f"      - Timestamp: {self.last_save_time.isoformat()}")
            
            return True
            
        except Exception as e:
            print(f"âŒ Failed to save system state: {e}")
            return False
    
    def load_system_state(self, universal_system, fractal_system, ai_system,
                         self_gen_system, vibrational_system, governance_system) -> bool:
        """
        Restore system state from file
        
        Args:
            universal_system: Universal Knowledge Representation System
            fractal_system: Fractal Recursion System
            ai_system: Advanced AI Integration System
            self_gen_system: Self-Generating System
            vibrational_system: Vibrational Axes System
            governance_system: Resonance Governance System
        
        Returns:
            True if load successful, False otherwise
        """
        try:
            if not self.persistence_file.exists():
                print(f"âš ï¸ No persistence file found: {self.persistence_file}")
                return False
            
            print(f"\nðŸ”„ Loading Living Codex system state...")
            
            # Load state from file
            with open(self.persistence_file, 'r') as f:
                state = json.load(f)
            
            self.state = state
            self.last_load_time = datetime.now()
            
            # Restore universal system
            print(f"   ðŸ”„ Restoring universal system...")
            universal_system.universal_concepts = self._deserialize_concepts(state["universal_system"]["universal_concepts"])
            universal_system.concept_transformations = self._deserialize_transformations(state["universal_system"]["concept_transformations"])
            universal_system.meta_circular_architectures = self._deserialize_meta_circular_architectures(state["universal_system"]["meta_circular_architectures"])
            universal_system.knowledge_expansions = self._deserialize_expansions(state["universal_system"]["knowledge_expansions"])
            universal_system.concept_to_node_mapping = state["universal_system"]["concept_to_node_mapping"]
            universal_system.node_to_concept_mapping = state["universal_system"]["node_to_concept_mapping"]
            
            # Restore fractal system
            print(f"   ðŸ”„ Restoring fractal system...")
            fractal_system.fractal_nodes = self._deserialize_fractal_nodes(state["fractal_system"]["fractal_nodes"])
            fractal_system.fractal_relationships = defaultdict(set)
            for k, v in state["fractal_system"]["fractal_relationships"].items():
                fractal_system.fractal_relationships[k] = set(v)
            fractal_system.cross_scale_mappings = state["fractal_system"]["cross_scale_mappings"]
            fractal_system.fractal_patterns = set(state["fractal_system"]["fractal_patterns"])
            fractal_system.exploration_cache = state["fractal_system"]["exploration_cache"]
            
            # Restore AI system
            print(f"   ðŸ”„ Restoring AI system...")
            ai_system.ai_agents = self._deserialize_ai_agents(state["ai_system"]["ai_agents"])
            ai_system.consciousness_decisions = self._deserialize_decisions(state["ai_system"]["consciousness_decisions"])
            ai_system.autonomous_explorations = self._deserialize_explorations(state["ai_system"]["autonomous_explorations"])
            ai_system.ai_evolutions = self._deserialize_evolutions(state["ai_system"]["ai_evolutions"])
            ai_system.agent_consciousness_history = defaultdict(list)
            for k, v in state["ai_system"]["agent_consciousness_history"].items():
                ai_system.agent_consciousness_history[k] = v
            
            # Restore self-generating system
            print(f"   ðŸ”„ Restoring self-generating system...")
            self_gen_system.discovered_concepts = self._deserialize_concepts(state["self_gen_system"]["discovered_concepts"])
            self_gen_system.generated_specifications = self._serialize_specifications(state["self_gen_system"]["generated_specifications"])
            self_gen_system.ontological_evolutions = self._deserialize_evolutions(state["self_gen_system"]["ontological_evolutions"])
            self_gen_system.concept_relationships = defaultdict(set)
            for k, v in state["self_gen_system"]["concept_relationships"].items():
                self_gen_system.concept_relationships[k] = v
            self_gen_system.evolution_history = state["self_gen_system"]["evolution_history"]
            
            # Restore vibrational system
            print(f"   ðŸ”„ Restoring vibrational system...")
            vibrational_system.vibrational_axes = state["vibrational_system"]["vibrational_axes"]
            vibrational_system.resonance_states = defaultdict(dict)
            for k, v in state["vibrational_system"]["resonance_states"].items():
                vibrational_system.resonance_states[k] = v
            vibrational_system.community_resonance = defaultdict(dict)
            for k, v in state["vibrational_system"]["community_resonance"].items():
                vibrational_system.community_resonance[k] = v
            vibrational_system.fractal_recursion_cache = state["vibrational_system"]["fractal_recursion_cache"]
            vibrational_system.cross_scale_cache = state["vibrational_system"]["cross_scale_cache"]
            
            # Restore governance system
            print(f"   ðŸ”„ Restoring governance system...")
            governance_system.resonance_decisions = self._deserialize_decisions(state["governance_system"]["resonance_decisions"])
            governance_system.coherence_fields = self._serialize_fields(state["governance_system"]["coherence_fields"])
            governance_system.collective_intelligence = self._serialize_intelligence(state["governance_system"]["collective_intelligence"])
            governance_system.node_resonance_history = defaultdict(list)
            for k, v in state["governance_system"]["node_resonance_history"].items():
                governance_system.node_resonance_history[k] = v
            governance_system.system_coherence_history = state["governance_system"]["system_coherence_history"]
            governance_system.governance_rules = state["governance_system"]["governance_rules"]
            
            # Calculate statistics
            total_concepts = len(universal_system.universal_concepts)
            total_fractal_nodes = len(fractal_system.fractal_nodes)
            total_ai_agents = len(ai_system.ai_agents)
            
            print(f"âœ… System state restored successfully!")
            print(f"   ðŸ“Š Statistics:")
            print(f"      - Universal concepts: {total_concepts}")
            print(f"      - Fractal nodes: {total_fractal_nodes}")
            print(f"      - AI agents: {total_ai_agents}")
            print(f"      - Load time: {self.last_load_time.isoformat()}")
            print(f"      - Original save time: {state['metadata']['save_timestamp']}")
            
            return True
            
        except Exception as e:
            print(f"âŒ Failed to load system state: {e}")
            return False
    
    def get_system_info(self) -> Dict[str, Any]:
        """Get information about the current persistence state"""
        info = {
            "persistence_file": str(self.persistence_file),
            "file_exists": self.persistence_file.exists(),
            "last_save_time": self.last_save_time.isoformat() if self.last_save_time else None,
            "last_load_time": self.last_load_time.isoformat() if self.last_load_time else None,
            "current_state_size": len(self.state) if self.state else 0
        }
        
        if self.persistence_file.exists():
            info["file_size_bytes"] = self.persistence_file.stat().st_size
            info["file_size_mb"] = round(info["file_size_bytes"] / (1024 * 1024), 2)
            info["file_modified"] = datetime.fromtimestamp(self.persistence_file.stat().st_mtime).isoformat()
        
        return info
    
    def _serialize_concepts(self, concepts: Dict[str, Any]) -> Dict[str, Any]:
        """Serialize concepts for JSON storage"""
        serialized = {}
        for k, v in concepts.items():
            if hasattr(v, '__dict__'):
                # Handle enums properly
                concept_dict = {}
                for attr_name, attr_value in v.__dict__.items():
                    if hasattr(attr_value, 'value'):  # Enum
                        concept_dict[attr_name] = attr_value.value
                    else:
                        concept_dict[attr_name] = attr_value
                serialized[k] = concept_dict
            else:
                serialized[k] = v
        return serialized
    
    def _deserialize_concepts(self, concepts: Dict[str, Any]) -> Dict[str, Any]:
        """Deserialize concepts from JSON storage, reconstructing UniversalConcept objects."""
        deserialized = {}
        from universal_knowledge_representation_system import UniversalConcept
        from living_codex_ontology import EpistemicLabel, ConsciousnessLevel # Import necessary enums

        for concept_id, concept_data in concepts.items():
            if isinstance(concept_data, dict):
                try:
                    # Reconstruct UniversalConcept object
                    # Handle enum types for EpistemicLabel and ConsciousnessLevel
                    epistemic_label_value = concept_data.get('epistemic_label', EpistemicLabel.SPECULATIVE.value)
                    if isinstance(epistemic_label_value, str) and 'EpistemicLabel.' in epistemic_label_value:
                        epistemic_label_value = epistemic_label_value.split('.')[-1]
                    epistemic_label = EpistemicLabel(epistemic_label_value)

                    consciousness_requirements_values = concept_data.get('consciousness_requirements', [])
                    consciousness_requirements = []
                    for cr_value in consciousness_requirements_values:
                        if isinstance(cr_value, str) and 'ConsciousnessLevel.' in cr_value:
                            cr_value = cr_value.split('.')[-1]
                        try:
                            consciousness_requirements.append(ConsciousnessLevel(cr_value))
                        except ValueError:
                            print(f"âš ï¸ Warning: Invalid ConsciousnessLevel value '{cr_value}' for concept {concept_id}")
                            # Fallback or skip invalid values
                            pass

                    concept = UniversalConcept(
                        concept_id=concept_id,
                        name=concept_data.get('name', 'Unknown Concept'),
                        description=concept_data.get('description', 'No description'),
                        concept_type=concept_data.get('concept_type', 'abstract'),
                        ontological_properties=concept_data.get('ontological_properties', {}),
                        vibrational_axes=concept_data.get('vibrational_axes', []),
                        fractal_relationships=concept_data.get('fractal_relationships', {}),
                        consciousness_requirements=consciousness_requirements,
                        epistemic_foundations=[EpistemicLabel(ef_val.split('.')[-1] if isinstance(ef_val, str) and 'EpistemicLabel.' in ef_val else ef_val) for ef_val in concept_data.get('epistemic_foundations', [])],
                        creation_timestamp=concept_data.get('creation_timestamp', datetime.now().isoformat()),
                        last_updated=concept_data.get('last_updated', datetime.now().isoformat()),
                        living_node_id=concept_data.get('living_node_id'),
                        epistemic_label=epistemic_label
                    )
                    deserialized[concept_id] = concept
                except Exception as e:
                    print(f"âš ï¸ Warning: Could not reconstruct concept {concept_id}: {e}")
                    # Fallback to dictionary if reconstruction fails
                    deserialized[concept_id] = concept_data
            else:
                deserialized[concept_id] = concept_data
        return deserialized
    
    def _serialize_transformations(self, transformations: Dict[str, Any]) -> Dict[str, Any]:
        """Serialize transformations for JSON storage"""
        return self._serialize_concepts(transformations)
    
    def _deserialize_transformations(self, transformations: Dict[str, Any]) -> Dict[str, Any]:
        """Deserialize transformations from JSON storage"""
        return self._deserialize_concepts(transformations)
    
    def _serialize_architectures(self, architectures: Dict[str, Any]) -> Dict[str, Any]:
        """Serialize architectures for JSON storage"""
        return self._serialize_concepts(architectures)
    
    def _deserialize_meta_circular_architectures(self, architectures: Dict[str, Any]) -> Dict[str, Any]:
        """Deserialize meta-circular architectures from JSON storage"""
        deserialized = {}
        for arch_id, arch_data in architectures.items():
            if isinstance(arch_data, dict):
                try:
                    from universal_knowledge_representation_system import MetaCircularArchitecture
                    from living_codex_ontology import EpistemicLabel
                    
                    # Extract properties
                    system_components = arch_data.get('system_components', [])
                    self_descriptions = arch_data.get('self_descriptions', [])
                    meta_implementations = arch_data.get('meta_implementations', [])
                    circular_relationships = arch_data.get('circular_relationships', [])
                    architecture_confidence = arch_data.get('architecture_confidence', 0.5)
                    completeness_score = arch_data.get('completeness_score', 0.5)
                    created_at = arch_data.get('created_at', datetime.now().isoformat())
                    epistemic_label_value = arch_data.get('epistemic_label', 'speculative')
                    
                    # Handle epistemic label
                    if isinstance(epistemic_label_value, str) and 'EpistemicLabel.' in epistemic_label_value:
                        epistemic_label_value = epistemic_label_value.split('.')[-1]
                    epistemic_label = EpistemicLabel(epistemic_label_value)
                    
                    # Create MetaCircularArchitecture object
                    architecture = MetaCircularArchitecture(
                        architecture_id=arch_id,
                        system_components=system_components,
                        self_descriptions=self_descriptions,
                        meta_implementations=meta_implementations,
                        circular_relationships=circular_relationships,
                        architecture_confidence=architecture_confidence,
                        completeness_score=completeness_score,
                        created_at=created_at,
                        epistemic_label=epistemic_label
                    )
                    
                    deserialized[arch_id] = architecture
                except Exception as e:
                    print(f"âš ï¸ Warning: Could not reconstruct meta-circular architecture {arch_id}: {e}")
                    deserialized[arch_id] = arch_data
            else:
                deserialized[arch_id] = arch_data
        
        return deserialized
    
    def _serialize_expansions(self, expansions: Dict[str, Any]) -> Dict[str, Any]:
        """Serialize expansions for JSON storage"""
        return self._serialize_concepts(expansions)
    
    def _deserialize_expansions(self, expansions: Dict[str, Any]) -> Dict[str, Any]:
        """Deserialize knowledge expansions from JSON storage"""
        deserialized = {}
        for expansion_id, expansion_data in expansions.items():
            if isinstance(expansion_data, dict):
                try:
                    from universal_knowledge_representation_system import InfiniteKnowledgeExpansion
                    from living_codex_ontology import EpistemicLabel
                    
                    # Extract properties
                    expansion_type = expansion_data.get('expansion_type', 'generic')
                    new_concepts_discovered = expansion_data.get('new_concepts_discovered', [])
                    knowledge_boundaries_pushed = expansion_data.get('knowledge_boundaries_pushed', [])
                    expansion_confidence = expansion_data.get('expansion_confidence', 0.5)
                    infinite_potential_score = expansion_data.get('infinite_potential_score', 0.5)
                    created_at = expansion_data.get('created_at', datetime.now().isoformat())
                    epistemic_label_value = expansion_data.get('epistemic_label', 'speculative')
                    
                    # Handle epistemic label
                    if isinstance(epistemic_label_value, str) and 'EpistemicLabel.' in epistemic_label_value:
                        epistemic_label_value = epistemic_label_value.split('.')[-1]
                    epistemic_label = EpistemicLabel(epistemic_label_value)
                    
                    # Create InfiniteKnowledgeExpansion object
                    expansion = InfiniteKnowledgeExpansion(
                        expansion_id=expansion_id,
                        expansion_type=expansion_type,
                        new_concepts_discovered=new_concepts_discovered,
                        knowledge_boundaries_pushed=knowledge_boundaries_pushed,
                        expansion_confidence=expansion_confidence,
                        infinite_potential_score=infinite_potential_score,
                        created_at=created_at,
                        epistemic_label=epistemic_label
                    )
                    
                    deserialized[expansion_id] = expansion
                except Exception as e:
                    print(f"âš ï¸ Warning: Could not reconstruct knowledge expansion {expansion_id}: {e}")
                    deserialized[expansion_id] = expansion_data
            else:
                deserialized[expansion_id] = expansion_data
        
        return deserialized
    
    def _serialize_fractal_nodes(self, nodes: Dict[str, Any]) -> Dict[str, Any]:
        """Serialize fractal nodes for JSON storage"""
        return self._serialize_concepts(nodes)
    
    def _deserialize_fractal_nodes(self, nodes: Dict[str, Any]) -> Dict[str, Any]:
        """Deserialize fractal nodes from JSON storage"""
        deserialized = {}
        for node_id, node_data in nodes.items():
            if isinstance(node_data, dict):
                # Reconstruct FractalNode object
                try:
                    from fractal_recursion_system import FractalNode, FractalLayer
                    from living_codex_ontology import EpistemicLabel

                    # Extract basic properties
                    name = node_data.get('name', 'Unknown Node')
                    fractal_layer_value = node_data.get('fractal_layer', 2)
                    # Handle both enum values and string representations
                    if isinstance(fractal_layer_value, str) and 'FractalLayer.' in fractal_layer_value:
                        # Extract the numeric value from the enum string
                        try:
                            fractal_layer_value = int(fractal_layer_value.split('.')[-1])
                        except (ValueError, IndexError):
                            fractal_layer_value = 2  # Default fallback
                    fractal_layer = FractalLayer(fractal_layer_value)
                    has_part = node_data.get('has_part', [])
                    is_part_of = node_data.get('is_part_of')
                    fractal_depth = node_data.get('fractal_depth', 0)
                    self_similarity_score = node_data.get('self_similarity_score', 0.0)
                    cross_scale_mapping = node_data.get('cross_scale_mapping', {})
                    fractal_patterns = node_data.get('fractal_patterns', [])
                    metadata = node_data.get('metadata', {})
                    epistemic_label_value = node_data.get('epistemic_label', 'engineering')
                    # Handle both enum values and string representations
                    if isinstance(epistemic_label_value, str) and 'EpistemicLabel.' in epistemic_label_value:
                        try:
                            epistemic_label_value = epistemic_label_value.split('.')[-1]
                        except IndexError:
                            epistemic_label_value = 'engineering'
                    epistemic_label = EpistemicLabel(epistemic_label_value)

                    # Create the fractal node object
                    node = FractalNode(
                        node_id=node_id,
                        name=name,
                        fractal_layer=fractal_layer,
                        has_part=has_part,
                        is_part_of=is_part_of,
                        fractal_depth=fractal_depth,
                        self_similarity_score=self_similarity_score,
                        cross_scale_mapping=cross_scale_mapping,
                        fractal_patterns=fractal_patterns,
                        metadata=metadata,
                        epistemic_label=epistemic_label
                    )

                    deserialized[node_id] = node
                except Exception as e:
                    print(f"âš ï¸ Warning: Could not reconstruct fractal node {node_id}: {e}")
                    # Fallback to dictionary if reconstruction fails
                    deserialized[node_id] = node_data
            else:
                deserialized[node_id] = node_data

        return deserialized
    
    def _serialize_ai_agents(self, agents: Dict[str, Any]) -> Dict[str, Any]:
        """Serialize AI agents for JSON storage"""
        return self._serialize_concepts(agents)
    
    def _deserialize_ai_agents(self, agents: Dict[str, Any]) -> Dict[str, Any]:
        """Deserialize AI agents from JSON storage"""
        return self._deserialize_concepts(agents)
    
    def _serialize_decisions(self, decisions: Dict[str, Any]) -> Dict[str, Any]:
        """Serialize decisions for JSON storage"""
        return self._serialize_concepts(decisions)
    
    def _deserialize_decisions(self, decisions: Dict[str, Any]) -> Dict[str, Any]:
        """Deserialize decisions from JSON storage"""
        return self._deserialize_concepts(decisions)
    
    def _serialize_explorations(self, explorations: Dict[str, Any]) -> Dict[str, Any]:
        """Serialize explorations for JSON storage"""
        return self._serialize_concepts(explorations)
    
    def _deserialize_explorations(self, explorations: Dict[str, Any]) -> Dict[str, Any]:
        """Deserialize explorations from JSON storage"""
        return self._deserialize_concepts(explorations)
    
    def _serialize_evolutions(self, evolutions: Dict[str, Any]) -> Dict[str, Any]:
        """Serialize evolutions for JSON storage"""
        return self._serialize_concepts(evolutions)
    
    def _deserialize_evolutions(self, evolutions: Dict[str, Any]) -> Dict[str, Any]:
        """Deserialize evolutions from JSON storage"""
        return self._deserialize_concepts(evolutions)
    
    def _serialize_fields(self, fields: Dict[str, Any]) -> Dict[str, Any]:
        """Serialize fields for JSON storage"""
        return self._serialize_concepts(fields)
    
    def _deserialize_fields(self, fields: Dict[str, Any]) -> Dict[str, Any]:
        """Deserialize fields from JSON storage"""
        return self._deserialize_concepts(fields)
    
    def _serialize_intelligence(self, intelligence: Dict[str, Any]) -> Dict[str, Any]:
        """Serialize intelligence for JSON storage"""
        return self._serialize_concepts(intelligence)
    
    def _deserialize_intelligence(self, intelligence: Dict[str, Any]) -> Dict[str, Any]:
        """Deserialize intelligence from JSON storage"""
        return self._deserialize_concepts(intelligence)
    
    def _serialize_specifications(self, specifications: Dict[str, Any]) -> Dict[str, Any]:
        """Serialize specifications for JSON storage"""
        return self._serialize_concepts(specifications)
    
    def _deserialize_specifications(self, specifications: Dict[str, Any]) -> Dict[str, Any]:
        """Deserialize specifications from JSON storage"""
        return self._deserialize_concepts(specifications)
